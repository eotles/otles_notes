---
title: "Using natural language processing to determine factors associated with high‐quality feedback"
categories:
  - Blog
  - Research
tags:
  - Blog
  - Research
  - medicine
  - healthcare
  - artificial intelligence
  - machine learning
  - natural language processing
  - medical education
  - SIMPL
---

Global Surgical Education. Can be found [here](https://doi.org/10.1007/s44186-022-00051-y).


<iframe src="{{ site.url }}{{ site.baseurl }}/assets/papers/using_NLP_to_determine_factors_associated_with_high_quality_feedback.pdf.pdf" 
    style="aspect-ratio: 8.5 / 11;"
    width="100%" 
>
</iframe>

[Download paper.]({{ site.url }}{{ site.baseurl }}/assets/papers/using_NLP_to_determine_factors_associated_with_high_quality_feedback.pdf.pdf)


## Abstract
### Purpose
Feedback is a cornerstone of medical education. However, not all feedback that residents receive is high-quality. Natural language processing (NLP) can be used to efficiently examine the quality of large amounts of feedback. We used a validated NLP model to examine factors associated with the quality of feedback that general surgery trainees received on 24,531 workplace-based assessments of operative performance.

### Methods
We analyzed transcribed, dictated feedback from the Society for Improving Medical Professional Learning’s (SIMPL) smartphone-based app. We first applied a validated NLP model to all SIMPL evaluations that had dictated feedback, which resulted in a predicted probability that an instance of feedback was “relevant”, “specific”, and/or “corrective.” Higher predicted probabilities signaled an increased likelihood that feedback was high quality. We then used linear mixed-effects models to examine variation in predictive probabilities across programs, attending surgeons, trainees, procedures, autonomy granted, operative performance level, case complexity, and a trainee’s level of clinical training.

### Results
Linear mixed-effects modeling demonstrated that predicted probabilities, i.e., a proxy for quality, were lower as operative autonomy increased (“Passive Help” B = − 1.29, p &lt; .001; “Supervision Only” B = − 5.53, p &lt; 0.001). Similarly, trainees who demonstrated “Exceptional Performance” received lower quality feedback (B = − 12.50, p &lt; 0.001). The specific procedure or trainee did not have a large effect on quality, nor did the complexity of the case or the PGY level of a trainee. The individual faculty member providing the feedback, however, had a demonstrable impact on quality with approximately 36% of the variation in quality attributable to attending surgeons.

### Conclusions
We were able to identify actionable items affecting resident feedback quality using an NLP model. Attending surgeons are the most influential factor in whether feedback is high quality. Faculty should be directly engaged in efforts to improve the overall quality of feedback that residents receive.
